{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import SparsePCA\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_num_components(a):\n",
    "    num_pairs = len(a)\n",
    "    num_components = int(np.ceil(np.sqrt(2 * num_pairs - 1)))\n",
    "    if num_components * (num_components - 1) == 2 * num_pairs:\n",
    "        return num_components\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def return_dfnc_from_vector(a):\n",
    "    '''This Function returns a dfnc matrix given a vector\n",
    "        a : the vector of correlation pairs\n",
    "    '''\n",
    "    n = calc_num_components(a)\n",
    "    out = np.zeros((n, n))\n",
    "\n",
    "    if not n:\n",
    "        return out\n",
    "    \n",
    "    l_indices = np.tril_indices(n, -1)\n",
    "    u_indices = np.triu_indices(n, 1)\n",
    "\n",
    "    out[u_indices] = a\n",
    "    out[l_indices] = out.T[l_indices]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "cwd = os.path.dirname(os.getcwd())\n",
    "data_dir = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "doc_dir = os.path.join(os.path.dirname(os.getcwd()), 'docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfnc_pairs = sio.loadmat(os.path.join(data_dir,'sfnc_pairs.mat'))\n",
    "sfnc_corr_pairs = sfnc_pairs['fnc_corrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = pd.read_excel(os.path.join(data_dir, '20160420_vcalhoun_rest_demography_cag_info_new.xls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sfnc_corr_pairs\n",
    "y = demographics.cap_d_group_id2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_diagnosis = demographics[\"visit_diagnosis_ID\"].values\n",
    "X_controls = X[y==0]\n",
    "#random subset\n",
    "control_subset = np.random.randint(0, high=78, size=23)\n",
    "X_controls_subset = X_controls[control_subset].copy()\n",
    "X_diagnosed = X[y_diagnosis==1]\n",
    "X_HD_diagnosed = pd.concat([pd.DataFrame(X_diagnosed), pd.DataFrame(X_controls_subset)], axis=0)\n",
    "y_HD_diagnosed = np.append(np.ones(23), np.zeros(23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create HD_near and Control samples\n",
    "#demographics[\"HD_near\"] = (demographics.cap_d_score > demographics.cap_d_score.dropna().median())*1\n",
    "demographics[\"HD_near\"] =  (demographics.cap_d_group==\"high\")*1\n",
    "X_near = X[demographics[\"HD_near\"]==1]\n",
    "X_controls = X[y==0]\n",
    "y_near = np.ones(np.sum(demographics[\"HD_near\"]))\n",
    "y_controls = np.zeros(78)\n",
    "# concatenate HD_near and controls\n",
    "X_HD_near = pd.concat([pd.DataFrame(X_near), pd.DataFrame(X_controls)], axis=0)\n",
    "y_HD_near = np.append(y_near, y_controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical: Expert informed order of domains: Diagnosed HD patients vs controls: Gradient boosting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_HD_diagnosed, y_HD_diagnosed, test_size=0.3, random_state=42)\n",
    "\n",
    "# Reduce to domains in Training data\n",
    "sfnc_corr_pairs = np.array(X_train)\n",
    "X_AUD_2 = np.concatenate((sfnc_corr_pairs[:,0:2], sfnc_corr_pairs[:,45].reshape(-1,1)), axis=1)\n",
    "X_CB_2 = np.concatenate((sfnc_corr_pairs[:,89:91], sfnc_corr_pairs[:,132].reshape(-1,1)), axis=1)\n",
    "X_CC_2 = np.concatenate((sfnc_corr_pairs[:,215:221],sfnc_corr_pairs[:,255:260],sfnc_corr_pairs[:,294:298],sfnc_corr_pairs[:,332:335], sfnc_corr_pairs[:,369:371], sfnc_corr_pairs[:,405].reshape(-1,1)), axis=1)\n",
    "X_DMN_2 = np.concatenate((sfnc_corr_pairs[:,474:488],sfnc_corr_pairs[:,507:520],sfnc_corr_pairs[:,539:551],sfnc_corr_pairs[:,570:581],sfnc_corr_pairs[:,600:610],sfnc_corr_pairs[:,629:638],sfnc_corr_pairs[:,657:665],sfnc_corr_pairs[:,684:691],sfnc_corr_pairs[:,710:716],sfnc_corr_pairs[:,735:740],sfnc_corr_pairs[:,759:763],sfnc_corr_pairs[:,782:785],sfnc_corr_pairs[:,804:806],sfnc_corr_pairs[:,825].reshape(-1,1)), axis=1)\n",
    "X_SC_2 = sfnc_corr_pairs[:,882:883].copy()\n",
    "X_VIS_2 = np.concatenate((sfnc_corr_pairs[:,980:990],sfnc_corr_pairs[:,990:999], sfnc_corr_pairs[:,999:1007], sfnc_corr_pairs[:,1007:1014],sfnc_corr_pairs[:,1014:1020],sfnc_corr_pairs[:,1020:1025],sfnc_corr_pairs[:,1025:1029],sfnc_corr_pairs[:,1029:1032], sfnc_corr_pairs[:,1032:1034], sfnc_corr_pairs[:,1034:1035]), axis=1)\n",
    "X_SM_2 = np.concatenate((sfnc_corr_pairs[:,915:919],sfnc_corr_pairs[:,930:933],sfnc_corr_pairs[:,944:946],sfnc_corr_pairs[:,957:958],), axis=1)           \n",
    "\n",
    "# Reduce to domains in Training data\n",
    "sfnc_corr_pairs = np.array(X_test)\n",
    "X_AUD_2_test = np.concatenate((sfnc_corr_pairs[:,0:2], sfnc_corr_pairs[:,45].reshape(-1,1)), axis=1)\n",
    "X_CB_2_test = np.concatenate((sfnc_corr_pairs[:,89:91], sfnc_corr_pairs[:,132].reshape(-1,1)), axis=1)\n",
    "X_CC_2_test = np.concatenate((sfnc_corr_pairs[:,215:221],sfnc_corr_pairs[:,255:260],sfnc_corr_pairs[:,294:298],sfnc_corr_pairs[:,332:335], sfnc_corr_pairs[:,369:371], sfnc_corr_pairs[:,405].reshape(-1,1)), axis=1)\n",
    "X_DMN_2_test = np.concatenate((sfnc_corr_pairs[:,474:488],sfnc_corr_pairs[:,507:520],sfnc_corr_pairs[:,539:551],sfnc_corr_pairs[:,570:581],sfnc_corr_pairs[:,600:610],sfnc_corr_pairs[:,629:638],sfnc_corr_pairs[:,657:665],sfnc_corr_pairs[:,684:691],sfnc_corr_pairs[:,710:716],sfnc_corr_pairs[:,735:740],sfnc_corr_pairs[:,759:763],sfnc_corr_pairs[:,782:785],sfnc_corr_pairs[:,804:806],sfnc_corr_pairs[:,825].reshape(-1,1)), axis=1)\n",
    "X_SC_2_test = sfnc_corr_pairs[:,882:883].copy()\n",
    "X_VIS_2_test = np.concatenate((sfnc_corr_pairs[:,980:990],sfnc_corr_pairs[:,990:999], sfnc_corr_pairs[:,999:1007], sfnc_corr_pairs[:,1007:1014],sfnc_corr_pairs[:,1014:1020],sfnc_corr_pairs[:,1020:1025],sfnc_corr_pairs[:,1025:1029],sfnc_corr_pairs[:,1029:1032], sfnc_corr_pairs[:,1032:1034], sfnc_corr_pairs[:,1034:1035]), axis=1)\n",
    "X_SM_2_test = np.concatenate((sfnc_corr_pairs[:,915:919],sfnc_corr_pairs[:,930:933],sfnc_corr_pairs[:,944:946],sfnc_corr_pairs[:,957:958],), axis=1)           \n",
    "\n",
    "y_training = np.zeros((7, np.shape(X_train)[0]))\n",
    "y_testing = np.zeros((7, np.shape(X_test)[0]))\n",
    "score = np.zeros((7,np.shape(X_test)[0]))\n",
    "domains = [X_SC_2, X_SM_2, X_CC_2, X_DMN_2, X_VIS_2, X_CB_2, X_AUD_2, ]\n",
    "domains_test = [X_SC_2_test, X_SM_2_test, X_CC_2_test, X_DMN_2_test, X_VIS_2_test, X_CB_2_test, X_AUD_2_test, ]\n",
    "\n",
    "# Fit & Test classifier one domain adter another\n",
    "for n, d, d_test in zip(range(0,7,1), domains, domains_test):\n",
    "    if n == 0:\n",
    "        gbc = GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                               max_features='log2',\n",
    "                                         loss = \"deviance\", max_depth=3, n_estimators=500)\n",
    "        gbc.fit(d, y_train)\n",
    "        y_training[n] = gbc.predict(d)\n",
    "        y_testing[n] = gbc.predict(d_test)\n",
    "    elif n !=0:\n",
    "        X_train = np.concatenate((d, y_training[n-1].reshape(-1,1)), axis=1)\n",
    "        gbc = GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                               max_features='log2',\n",
    "                                         loss = \"deviance\", max_depth=3, n_estimators=500)\n",
    "        gbc.fit(X_train, y_train)\n",
    "        y_training[n] = gbc.predict(X_train)\n",
    "        \n",
    "        X_test = np.concatenate((d_test, y_testing[n-1].reshape(-1,1)), axis=1)\n",
    "        y_testing[n] = gbc.predict(X_test)\n",
    "        score[n] = gbc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571],\n",
       "       [0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571],\n",
       "       [0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429],\n",
       "       [0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429],\n",
       "       [0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429],\n",
       "       [0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical: Expert informed order of domains: Diagnosed HD patients vs controls: Logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_HD_diagnosed, y_HD_diagnosed, test_size=0.3, random_state=42)\n",
    "\n",
    "# Reduce to domains in Training data\n",
    "sfnc_corr_pairs = np.array(X_train)\n",
    "X_AUD_2 = np.concatenate((sfnc_corr_pairs[:,0:2], sfnc_corr_pairs[:,45].reshape(-1,1)), axis=1)\n",
    "X_CB_2 = np.concatenate((sfnc_corr_pairs[:,89:91], sfnc_corr_pairs[:,132].reshape(-1,1)), axis=1)\n",
    "X_CC_2 = np.concatenate((sfnc_corr_pairs[:,215:221],sfnc_corr_pairs[:,255:260],sfnc_corr_pairs[:,294:298],sfnc_corr_pairs[:,332:335], sfnc_corr_pairs[:,369:371], sfnc_corr_pairs[:,405].reshape(-1,1)), axis=1)\n",
    "X_DMN_2 = np.concatenate((sfnc_corr_pairs[:,474:488],sfnc_corr_pairs[:,507:520],sfnc_corr_pairs[:,539:551],sfnc_corr_pairs[:,570:581],sfnc_corr_pairs[:,600:610],sfnc_corr_pairs[:,629:638],sfnc_corr_pairs[:,657:665],sfnc_corr_pairs[:,684:691],sfnc_corr_pairs[:,710:716],sfnc_corr_pairs[:,735:740],sfnc_corr_pairs[:,759:763],sfnc_corr_pairs[:,782:785],sfnc_corr_pairs[:,804:806],sfnc_corr_pairs[:,825].reshape(-1,1)), axis=1)\n",
    "X_SC_2 = sfnc_corr_pairs[:,882:883].copy()\n",
    "X_VIS_2 = np.concatenate((sfnc_corr_pairs[:,980:990],sfnc_corr_pairs[:,990:999], sfnc_corr_pairs[:,999:1007], sfnc_corr_pairs[:,1007:1014],sfnc_corr_pairs[:,1014:1020],sfnc_corr_pairs[:,1020:1025],sfnc_corr_pairs[:,1025:1029],sfnc_corr_pairs[:,1029:1032], sfnc_corr_pairs[:,1032:1034], sfnc_corr_pairs[:,1034:1035]), axis=1)\n",
    "X_SM_2 = np.concatenate((sfnc_corr_pairs[:,915:919],sfnc_corr_pairs[:,930:933],sfnc_corr_pairs[:,944:946],sfnc_corr_pairs[:,957:958],), axis=1)           \n",
    "\n",
    "# Reduce to domains in Training data\n",
    "sfnc_corr_pairs = np.array(X_test)\n",
    "X_AUD_2_test = np.concatenate((sfnc_corr_pairs[:,0:2], sfnc_corr_pairs[:,45].reshape(-1,1)), axis=1)\n",
    "X_CB_2_test = np.concatenate((sfnc_corr_pairs[:,89:91], sfnc_corr_pairs[:,132].reshape(-1,1)), axis=1)\n",
    "X_CC_2_test = np.concatenate((sfnc_corr_pairs[:,215:221],sfnc_corr_pairs[:,255:260],sfnc_corr_pairs[:,294:298],sfnc_corr_pairs[:,332:335], sfnc_corr_pairs[:,369:371], sfnc_corr_pairs[:,405].reshape(-1,1)), axis=1)\n",
    "X_DMN_2_test = np.concatenate((sfnc_corr_pairs[:,474:488],sfnc_corr_pairs[:,507:520],sfnc_corr_pairs[:,539:551],sfnc_corr_pairs[:,570:581],sfnc_corr_pairs[:,600:610],sfnc_corr_pairs[:,629:638],sfnc_corr_pairs[:,657:665],sfnc_corr_pairs[:,684:691],sfnc_corr_pairs[:,710:716],sfnc_corr_pairs[:,735:740],sfnc_corr_pairs[:,759:763],sfnc_corr_pairs[:,782:785],sfnc_corr_pairs[:,804:806],sfnc_corr_pairs[:,825].reshape(-1,1)), axis=1)\n",
    "X_SC_2_test = sfnc_corr_pairs[:,882:883].copy()\n",
    "X_VIS_2_test = np.concatenate((sfnc_corr_pairs[:,980:990],sfnc_corr_pairs[:,990:999], sfnc_corr_pairs[:,999:1007], sfnc_corr_pairs[:,1007:1014],sfnc_corr_pairs[:,1014:1020],sfnc_corr_pairs[:,1020:1025],sfnc_corr_pairs[:,1025:1029],sfnc_corr_pairs[:,1029:1032], sfnc_corr_pairs[:,1032:1034], sfnc_corr_pairs[:,1034:1035]), axis=1)\n",
    "X_SM_2_test = np.concatenate((sfnc_corr_pairs[:,915:919],sfnc_corr_pairs[:,930:933],sfnc_corr_pairs[:,944:946],sfnc_corr_pairs[:,957:958],), axis=1)           \n",
    "\n",
    "y_training = np.zeros((7, np.shape(X_train)[0]))\n",
    "y_testing = np.zeros((7, np.shape(X_test)[0]))\n",
    "score = np.zeros((7,np.shape(X_test)[0]))\n",
    "domains = [ X_SC_2, X_SM_2, X_CC_2, X_DMN_2, X_VIS_2, X_CB_2, X_AUD_2,]\n",
    "domains_test = [ X_SC_2_test, X_SM_2_test, X_CC_2_test, X_DMN_2_test, X_VIS_2_test, X_CB_2_test, X_AUD_2_test, ]\n",
    "\n",
    "# Fit & Test classifier one domain adter another\n",
    "for n, d, d_test in zip(range(0,7,1), domains, domains_test):\n",
    "    if n == 0:\n",
    "        gbc = LogisticRegression(solver=\"lbfgs\")\n",
    "        gbc.fit(d, y_train)\n",
    "        y_training[n] = gbc.predict(d)\n",
    "        y_testing[n] = gbc.predict(d_test)\n",
    "    elif n !=0:\n",
    "        X_train = np.concatenate((d, y_training[n-1].reshape(-1,1)), axis=1)\n",
    "        gbc = LogisticRegression(solver=\"lbfgs\")\n",
    "        gbc.fit(X_train, y_train)\n",
    "        y_training[n] = gbc.predict(X_train)\n",
    "        \n",
    "        X_test = np.concatenate((d_test, y_testing[n-1].reshape(-1,1)), axis=1)\n",
    "        y_testing[n] = gbc.predict(X_test)\n",
    "        score[n] = gbc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.64285714,\n",
       "        0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.64285714,\n",
       "        0.64285714, 0.64285714, 0.64285714, 0.64285714],\n",
       "       [0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.64285714,\n",
       "        0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.64285714,\n",
       "        0.64285714, 0.64285714, 0.64285714, 0.64285714],\n",
       "       [0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429],\n",
       "       [0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429],\n",
       "       [0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429],\n",
       "       [0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
       "        0.78571429, 0.78571429, 0.78571429, 0.78571429]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical: Expert informed order of domains: Late HD patients vs controls: Gradient boosting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_HD_near, y_HD_near, test_size=0.3, random_state=42)\n",
    "\n",
    "# Reduce to domains in Training data\n",
    "sfnc_corr_pairs = np.array(X_train)\n",
    "X_AUD_2 = np.concatenate((sfnc_corr_pairs[:,0:2], sfnc_corr_pairs[:,45].reshape(-1,1)), axis=1)\n",
    "X_CB_2 = np.concatenate((sfnc_corr_pairs[:,89:91], sfnc_corr_pairs[:,132].reshape(-1,1)), axis=1)\n",
    "X_CC_2 = np.concatenate((sfnc_corr_pairs[:,215:221],sfnc_corr_pairs[:,255:260],sfnc_corr_pairs[:,294:298],sfnc_corr_pairs[:,332:335], sfnc_corr_pairs[:,369:371], sfnc_corr_pairs[:,405].reshape(-1,1)), axis=1)\n",
    "X_DMN_2 = np.concatenate((sfnc_corr_pairs[:,474:488],sfnc_corr_pairs[:,507:520],sfnc_corr_pairs[:,539:551],sfnc_corr_pairs[:,570:581],sfnc_corr_pairs[:,600:610],sfnc_corr_pairs[:,629:638],sfnc_corr_pairs[:,657:665],sfnc_corr_pairs[:,684:691],sfnc_corr_pairs[:,710:716],sfnc_corr_pairs[:,735:740],sfnc_corr_pairs[:,759:763],sfnc_corr_pairs[:,782:785],sfnc_corr_pairs[:,804:806],sfnc_corr_pairs[:,825].reshape(-1,1)), axis=1)\n",
    "X_SC_2 = sfnc_corr_pairs[:,882:883].copy()\n",
    "X_VIS_2 = np.concatenate((sfnc_corr_pairs[:,980:990],sfnc_corr_pairs[:,990:999], sfnc_corr_pairs[:,999:1007], sfnc_corr_pairs[:,1007:1014],sfnc_corr_pairs[:,1014:1020],sfnc_corr_pairs[:,1020:1025],sfnc_corr_pairs[:,1025:1029],sfnc_corr_pairs[:,1029:1032], sfnc_corr_pairs[:,1032:1034], sfnc_corr_pairs[:,1034:1035]), axis=1)\n",
    "X_SM_2 = np.concatenate((sfnc_corr_pairs[:,915:919],sfnc_corr_pairs[:,930:933],sfnc_corr_pairs[:,944:946],sfnc_corr_pairs[:,957:958],), axis=1)           \n",
    "\n",
    "# Reduce to domains in Training data\n",
    "sfnc_corr_pairs = np.array(X_test)\n",
    "X_AUD_2_test = np.concatenate((sfnc_corr_pairs[:,0:2], sfnc_corr_pairs[:,45].reshape(-1,1)), axis=1)\n",
    "X_CB_2_test = np.concatenate((sfnc_corr_pairs[:,89:91], sfnc_corr_pairs[:,132].reshape(-1,1)), axis=1)\n",
    "X_CC_2_test = np.concatenate((sfnc_corr_pairs[:,215:221],sfnc_corr_pairs[:,255:260],sfnc_corr_pairs[:,294:298],sfnc_corr_pairs[:,332:335], sfnc_corr_pairs[:,369:371], sfnc_corr_pairs[:,405].reshape(-1,1)), axis=1)\n",
    "X_DMN_2_test = np.concatenate((sfnc_corr_pairs[:,474:488],sfnc_corr_pairs[:,507:520],sfnc_corr_pairs[:,539:551],sfnc_corr_pairs[:,570:581],sfnc_corr_pairs[:,600:610],sfnc_corr_pairs[:,629:638],sfnc_corr_pairs[:,657:665],sfnc_corr_pairs[:,684:691],sfnc_corr_pairs[:,710:716],sfnc_corr_pairs[:,735:740],sfnc_corr_pairs[:,759:763],sfnc_corr_pairs[:,782:785],sfnc_corr_pairs[:,804:806],sfnc_corr_pairs[:,825].reshape(-1,1)), axis=1)\n",
    "X_SC_2_test = sfnc_corr_pairs[:,882:883].copy()\n",
    "X_VIS_2_test = np.concatenate((sfnc_corr_pairs[:,980:990],sfnc_corr_pairs[:,990:999], sfnc_corr_pairs[:,999:1007], sfnc_corr_pairs[:,1007:1014],sfnc_corr_pairs[:,1014:1020],sfnc_corr_pairs[:,1020:1025],sfnc_corr_pairs[:,1025:1029],sfnc_corr_pairs[:,1029:1032], sfnc_corr_pairs[:,1032:1034], sfnc_corr_pairs[:,1034:1035]), axis=1)\n",
    "X_SM_2_test = np.concatenate((sfnc_corr_pairs[:,915:919],sfnc_corr_pairs[:,930:933],sfnc_corr_pairs[:,944:946],sfnc_corr_pairs[:,957:958],), axis=1)           \n",
    "\n",
    "y_training = np.zeros((7, np.shape(X_train)[0]))\n",
    "y_testing = np.zeros((7, np.shape(X_test)[0]))\n",
    "score = np.zeros((7,np.shape(X_test)[0]))\n",
    "domains = [X_SC_2, X_SM_2, X_CC_2, X_DMN_2, X_VIS_2, X_CB_2, X_AUD_2, ]\n",
    "domains_test = [X_SC_2_test, X_SM_2_test, X_CC_2_test, X_DMN_2_test, X_VIS_2_test, X_CB_2_test, X_AUD_2_test, ]\n",
    "\n",
    "# Fit & Test classifier one domain adter another\n",
    "for n, d, d_test in zip(range(0,7,1), domains, domains_test):\n",
    "    if n == 0:\n",
    "        gbc = GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                               max_features='log2',\n",
    "                                         loss = \"deviance\", max_depth=3, n_estimators=500)\n",
    "        gbc.fit(d, y_train)\n",
    "        y_training[n] = gbc.predict(d)\n",
    "        y_testing[n] = gbc.predict(d_test)\n",
    "    elif n !=0:\n",
    "        X_train = np.concatenate((d, y_training[n-1].reshape(-1,1)), axis=1)\n",
    "        gbc = GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                               max_features='log2',\n",
    "                                         loss = \"deviance\", max_depth=3, n_estimators=500)\n",
    "        gbc.fit(X_train, y_train)\n",
    "        y_training[n] = gbc.predict(X_train)\n",
    "        \n",
    "        X_test = np.concatenate((d_test, y_testing[n-1].reshape(-1,1)), axis=1)\n",
    "        y_testing[n] = gbc.predict(X_test)\n",
    "        score[n] = gbc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809],\n",
       "       [0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809],\n",
       "       [0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809],\n",
       "       [0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809],\n",
       "       [0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809],\n",
       "       [0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical: Expert informed order of domains: Late HD patients vs controls: Logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_HD_near, y_HD_near, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Reduce to domains in Training data\n",
    "sfnc_corr_pairs = np.array(X_train)\n",
    "X_AUD_2 = np.concatenate((sfnc_corr_pairs[:,0:2], sfnc_corr_pairs[:,45].reshape(-1,1)), axis=1)\n",
    "X_CB_2 = np.concatenate((sfnc_corr_pairs[:,89:91], sfnc_corr_pairs[:,132].reshape(-1,1)), axis=1)\n",
    "X_CC_2 = np.concatenate((sfnc_corr_pairs[:,215:221],sfnc_corr_pairs[:,255:260],sfnc_corr_pairs[:,294:298],sfnc_corr_pairs[:,332:335], sfnc_corr_pairs[:,369:371], sfnc_corr_pairs[:,405].reshape(-1,1)), axis=1)\n",
    "X_DMN_2 = np.concatenate((sfnc_corr_pairs[:,474:488],sfnc_corr_pairs[:,507:520],sfnc_corr_pairs[:,539:551],sfnc_corr_pairs[:,570:581],sfnc_corr_pairs[:,600:610],sfnc_corr_pairs[:,629:638],sfnc_corr_pairs[:,657:665],sfnc_corr_pairs[:,684:691],sfnc_corr_pairs[:,710:716],sfnc_corr_pairs[:,735:740],sfnc_corr_pairs[:,759:763],sfnc_corr_pairs[:,782:785],sfnc_corr_pairs[:,804:806],sfnc_corr_pairs[:,825].reshape(-1,1)), axis=1)\n",
    "X_SC_2 = sfnc_corr_pairs[:,882:883].copy()\n",
    "X_VIS_2 = np.concatenate((sfnc_corr_pairs[:,980:990],sfnc_corr_pairs[:,990:999], sfnc_corr_pairs[:,999:1007], sfnc_corr_pairs[:,1007:1014],sfnc_corr_pairs[:,1014:1020],sfnc_corr_pairs[:,1020:1025],sfnc_corr_pairs[:,1025:1029],sfnc_corr_pairs[:,1029:1032], sfnc_corr_pairs[:,1032:1034], sfnc_corr_pairs[:,1034:1035]), axis=1)\n",
    "X_SM_2 = np.concatenate((sfnc_corr_pairs[:,915:919],sfnc_corr_pairs[:,930:933],sfnc_corr_pairs[:,944:946],sfnc_corr_pairs[:,957:958],), axis=1)           \n",
    "\n",
    "# Reduce to domains in Training data\n",
    "sfnc_corr_pairs = np.array(X_test)\n",
    "X_AUD_2_test = np.concatenate((sfnc_corr_pairs[:,0:2], sfnc_corr_pairs[:,45].reshape(-1,1)), axis=1)\n",
    "X_CB_2_test = np.concatenate((sfnc_corr_pairs[:,89:91], sfnc_corr_pairs[:,132].reshape(-1,1)), axis=1)\n",
    "X_CC_2_test = np.concatenate((sfnc_corr_pairs[:,215:221],sfnc_corr_pairs[:,255:260],sfnc_corr_pairs[:,294:298],sfnc_corr_pairs[:,332:335], sfnc_corr_pairs[:,369:371], sfnc_corr_pairs[:,405].reshape(-1,1)), axis=1)\n",
    "X_DMN_2_test = np.concatenate((sfnc_corr_pairs[:,474:488],sfnc_corr_pairs[:,507:520],sfnc_corr_pairs[:,539:551],sfnc_corr_pairs[:,570:581],sfnc_corr_pairs[:,600:610],sfnc_corr_pairs[:,629:638],sfnc_corr_pairs[:,657:665],sfnc_corr_pairs[:,684:691],sfnc_corr_pairs[:,710:716],sfnc_corr_pairs[:,735:740],sfnc_corr_pairs[:,759:763],sfnc_corr_pairs[:,782:785],sfnc_corr_pairs[:,804:806],sfnc_corr_pairs[:,825].reshape(-1,1)), axis=1)\n",
    "X_SC_2_test = sfnc_corr_pairs[:,882:883].copy()\n",
    "X_VIS_2_test = np.concatenate((sfnc_corr_pairs[:,980:990],sfnc_corr_pairs[:,990:999], sfnc_corr_pairs[:,999:1007], sfnc_corr_pairs[:,1007:1014],sfnc_corr_pairs[:,1014:1020],sfnc_corr_pairs[:,1020:1025],sfnc_corr_pairs[:,1025:1029],sfnc_corr_pairs[:,1029:1032], sfnc_corr_pairs[:,1032:1034], sfnc_corr_pairs[:,1034:1035]), axis=1)\n",
    "X_SM_2_test = np.concatenate((sfnc_corr_pairs[:,915:919],sfnc_corr_pairs[:,930:933],sfnc_corr_pairs[:,944:946],sfnc_corr_pairs[:,957:958],), axis=1)           \n",
    "\n",
    "y_training = np.zeros((7, np.shape(X_train)[0]))\n",
    "y_testing = np.zeros((7, np.shape(X_test)[0]))\n",
    "score = np.zeros((7,np.shape(X_test)[0]))\n",
    "domains = [ X_SC_2, X_SM_2, X_CC_2, X_DMN_2, X_VIS_2, X_CB_2, X_AUD_2,]\n",
    "domains_test = [ X_SC_2_test, X_SM_2_test, X_CC_2_test, X_DMN_2_test, X_VIS_2_test, X_CB_2_test, X_AUD_2_test, ]\n",
    "\n",
    "# Fit & Test classifier one domain adter another\n",
    "for n, d, d_test in zip(range(0,7,1), domains, domains_test):\n",
    "    if n == 0:\n",
    "        gbc = LogisticRegression(solver=\"lbfgs\")\n",
    "        gbc.fit(d, y_train)\n",
    "        y_training[n] = gbc.predict(d)\n",
    "        y_testing[n] = gbc.predict(d_test)\n",
    "    elif n !=0:\n",
    "        X_train = np.concatenate((d, y_training[n-1].reshape(-1,1)), axis=1)\n",
    "        gbc = LogisticRegression(solver=\"lbfgs\")\n",
    "        gbc.fit(X_train, y_train)\n",
    "        y_training[n] = gbc.predict(X_train)\n",
    "        \n",
    "        X_test = np.concatenate((d_test, y_testing[n-1].reshape(-1,1)), axis=1)\n",
    "        y_testing[n] = gbc.predict(X_test)\n",
    "        score[n] = gbc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809, 0.57446809, 0.57446809, 0.57446809,\n",
       "        0.57446809, 0.57446809],\n",
       "       [0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 ,\n",
       "        0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 ,\n",
       "        0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 ,\n",
       "        0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 ,\n",
       "        0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 ,\n",
       "        0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 ,\n",
       "        0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 ,\n",
       "        0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 ,\n",
       "        0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 , 0.4893617 ,\n",
       "        0.4893617 , 0.4893617 ],\n",
       "       [0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 ],\n",
       "       [0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 ],\n",
       "       [0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 ],\n",
       "       [0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 , 0.5106383 ,\n",
       "        0.5106383 , 0.5106383 ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
